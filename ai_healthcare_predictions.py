# -*- coding: utf-8 -*-
"""AI Healthcare predictions

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UgirOI5dXZ1V6O10osKDmwFx9t9bPo5Z

### Import Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.cm import rainbow
import cv2
# %matplotlib inline
import openai
from IPython.display import HTML
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier



dataset = pd.read_csv('dataset.csv')

dataset.info()

dataset.describe()

### Understanding the data

rcParams['figure.figsize'] = 20, 14
plt.matshow(dataset.corr())
plt.yticks(np.arange(dataset.shape[1]), dataset.columns)
plt.xticks(np.arange(dataset.shape[1]), dataset.columns)
plt.colorbar()

dataset.hist()

rcParams['figure.figsize'] = 8,6
plt.bar(dataset['target'].unique(), dataset['target'].value_counts(), color = ['pink', 'blue'])
plt.xticks([0, 1])
plt.xlabel('Target Classes')
plt.ylabel('Count')
plt.title('Count of each Target Class')

### Data Processing

dataset = pd.get_dummies(dataset, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])

standardScaler = StandardScaler()
columns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
dataset[columns_to_scale] = standardScaler.fit_transform(dataset[columns_to_scale])

### Machine Learning


y = dataset['target']
X = dataset.drop(['target'], axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)

### K Neighbors Classifier

knn_scores = []
for k in range(1,21):
    knn_classifier = KNeighborsClassifier(n_neighbors = k)
    knn_classifier.fit(X_train, y_train)
    knn_scores.append(knn_classifier.score(X_test, y_test))

plt.plot([k for k in range(1, 21)], knn_scores, color = 'green')
for i in range(1,21):
    plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))
plt.xticks([i for i in range(1, 21)])
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Scores')
plt.title('K Neighbors Classifier scores for different K values')

print("The score for K Neighbors Classifier is {}% with {} nieghbors.".format(knn_scores[7]*100, 8))

###Using Matplotlib

heart_disease_count = 100
no_heart_disease_count = 200

categories = ['Heart Disease', 'No Heart Disease']
counts = [heart_disease_count, no_heart_disease_count]

plt.bar(categories, counts, color=['red', 'green'])
plt.title('Prevalence of Heart Disease')
plt.xlabel('Category')
plt.ylabel('Number of People')

###Decision Tree Clasifier

dt_scores = []
for i in range(1, len(X.columns) + 1):
    dt_classifier = DecisionTreeClassifier(max_features = i, random_state = 0)
    dt_classifier.fit(X_train, y_train)
    dt_scores.append(dt_classifier.score(X_test, y_test))

plt.plot([i for i in range(1, len(X.columns) + 1)], dt_scores, color = 'red')
for i in range(1, len(X.columns) + 1):
    plt.text(i, dt_scores[i-1], (i, dt_scores[i-1]))
plt.xticks([i for i in range(1, len(X.columns) + 1)])
plt.xlabel('Max features')
plt.ylabel('Scores')
plt.title('Decision Tree Classifier scores for different number of maximum features')

##The model achieved the best accuracy at three values of maximum features, `2`, `4` and `18`

print("The score for Decision Tree Classifier is {}% with {} maximum features.".format(dt_scores[17]*100, [2,4,18]))

##Random Forest Classifier

rf_scores = []
estimators = [10, 100, 200, 500, 1000]
for i in estimators:
    rf_classifier = RandomForestClassifier(n_estimators = i, random_state = 0)
    rf_classifier.fit(X_train, y_train)
    rf_scores.append(rf_classifier.score(X_test, y_test))

colors = rainbow(np.linspace(0, 1, len(estimators)))
plt.bar([i for i in range(len(estimators))], rf_scores, color = colors, width = 0.8)
for i in range(len(estimators)):
    plt.text(i, rf_scores[i], rf_scores[i])
plt.xticks(ticks = [i for i in range(len(estimators))], labels = [str(estimator) for estimator in estimators])
plt.xlabel('Number of estimators')
plt.ylabel('Scores')
plt.title('Random Forest Classifier scores for different number of estimators')
plt.show()

print("The score for Random Forest Classifier is {}% with {} estimators.".format(rf_scores[1]*100, [100, 500]))

### Logistic Regression

from sklearn.linear_model import LogisticRegression

logreg_classifier = LogisticRegression(random_state=0)
logreg_classifier.fit(X_train, y_train)

logreg_accuracy = logreg_classifier.score(X_test, y_test)
print(f"Accuracy of Logistic Regression: {logreg_accuracy * 100:.2f}%")

### Convolutional Neural Network (CNN)

import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_cnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)

model = keras.Sequential([
    layers.Conv1D(32, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    layers.MaxPooling1D(2),
    layers.Conv1D(64, 3, activation='relu'),
    layers.MaxPooling1D(2),
    layers.Flatten(),
    layers.Dense(10, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

X_test_cnn = np.nan_to_num(X_test_cnn)

y_pred = logreg_classifier.predict(X_test)

precision = precision_score(y_test, y_pred)

print(f"Precision: {precision:.4f}")

recall = recall_score(y_test, y_pred)

print(f"Recall: {recall:.4f}")

f1 = f1_score(y_test, y_pred)

print(f"F1 Score: {f1:.4f}")

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()



import streamlit as st

st.title("Health Assessment")

if 'message' not in st.session_state:
    st.session_state.message = ""

age = st.number_input("Age:", min_value=0, max_value=120, value=30)
smoker = st.selectbox("Smoker:", ["Yes", "No"])
diet = st.selectbox("Diet Type:", ["Healthy", "Unhealthy"])
exercise = st.selectbox("Exercise Level:", ["Low", "Moderate", "High"])

if st.button("Submit"):
    st.session_state.message = "Based on your inputs: "
    if age > 40 and smoker == "Yes":
        st.session_state.message += "You might be at higher risk for heart disease. "
    if diet == "Unhealthy":
        st.session_state.message += "Consider improving your diet. "
    if exercise == "Low":
        st.session_state.message += "Increasing your exercise level is recommended. "
    if st.session_state.message == "Based on your inputs: ":
        st.session_state.message += "You seem to be in good health!"

st.write(st.session_state.message)
